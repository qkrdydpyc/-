{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  1 0.28183361629881154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.19      0.18      0.19      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.45      0.25      0.32      1348\n",
      "           E       0.20      0.07      0.10      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.26      0.29      0.24      7068\n",
      "weighted avg       0.26      0.28      0.24      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  2 0.27560837577815506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.11      0.09      1500\n",
      "           B       0.19      0.18      0.19      1232\n",
      "           C       0.42      0.88      0.56      1400\n",
      "           D       0.50      0.22      0.30      1348\n",
      "           E       0.13      0.02      0.04      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.26      0.28      0.24      7068\n",
      "weighted avg       0.26      0.28      0.23      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  3 0.2801358234295416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.08      0.07      1500\n",
      "           B       0.20      0.18      0.19      1232\n",
      "           C       0.40      0.86      0.55      1400\n",
      "           D       0.48      0.27      0.34      1348\n",
      "           E       0.17      0.05      0.07      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.26      0.29      0.25      7068\n",
      "weighted avg       0.26      0.28      0.24      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  4 0.2812676853423882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.07      0.06      1500\n",
      "           B       0.21      0.18      0.20      1232\n",
      "           C       0.40      0.87      0.54      1400\n",
      "           D       0.48      0.27      0.35      1348\n",
      "           E       0.20      0.04      0.07      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.27      0.29      0.24      7068\n",
      "weighted avg       0.26      0.28      0.24      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  5 0.2869269949066214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.07      0.06      1500\n",
      "           B       0.23      0.21      0.22      1232\n",
      "           C       0.40      0.87      0.54      1400\n",
      "           D       0.51      0.29      0.37      1348\n",
      "           E       0.17      0.04      0.07      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.27      0.29      0.25      7068\n",
      "weighted avg       0.26      0.29      0.24      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  6 0.2903225806451613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.23      0.20      0.21      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.49      0.30      0.37      1348\n",
      "           E       0.24      0.05      0.08      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.28      0.30      0.25      7068\n",
      "weighted avg       0.28      0.29      0.25      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  7 0.29060554612337297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.22      0.20      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.50      0.31      0.38      1348\n",
      "           E       0.23      0.05      0.09      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.28      0.30      0.25      7068\n",
      "weighted avg       0.27      0.29      0.25      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  8 0.29485002829654783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.07      0.06      1500\n",
      "           B       0.23      0.19      0.21      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.49      0.31      0.38      1348\n",
      "           E       0.28      0.06      0.10      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.29      0.30      0.26      7068\n",
      "weighted avg       0.29      0.29      0.25      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  9 0.29470854555744197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.20      0.22      1232\n",
      "           C       0.39      0.87      0.54      1400\n",
      "           D       0.48      0.32      0.38      1348\n",
      "           E       0.29      0.06      0.10      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.29      0.30      0.26      7068\n",
      "weighted avg       0.29      0.29      0.25      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  10 0.2976796830786644\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.24      0.20      0.22      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.48      0.32      0.38      1348\n",
      "           E       0.32      0.07      0.11      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.26      7068\n",
      "weighted avg       0.29      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  11 0.29683078664402945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.23      0.20      0.21      1232\n",
      "           C       0.40      0.88      0.54      1400\n",
      "           D       0.48      0.33      0.39      1348\n",
      "           E       0.31      0.06      0.11      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.29      0.30      0.26      7068\n",
      "weighted avg       0.29      0.30      0.25      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  12 0.3027730616864743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.25      0.20      0.22      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.35      0.08      0.12      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  13 0.3010752688172043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.35      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  14 0.3048953027730617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.25      0.20      0.22      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.48      0.35      0.40      1348\n",
      "           E       0.37      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.31      0.31      0.27      7068\n",
      "weighted avg       0.31      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  15 0.30135823429541597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.87      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.36      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  16 0.3034804753820034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.35      0.41      1348\n",
      "           E       0.37      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.31      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  17 0.3034804753820034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.36      0.41      1348\n",
      "           E       0.36      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  18 0.3050367855121675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.36      0.41      1348\n",
      "           E       0.37      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.31      7068\n",
      "   macro avg       0.31      0.31      0.27      7068\n",
      "weighted avg       0.30      0.31      0.26      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  19 0.30475382003395585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.37      0.42      1348\n",
      "           E       0.36      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  1 0.28183361629881154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.19      0.18      0.19      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.45      0.25      0.32      1348\n",
      "           E       0.20      0.07      0.10      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.26      0.29      0.24      7068\n",
      "weighted avg       0.26      0.28      0.24      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  2 0.28183361629881154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.19      0.18      0.19      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.45      0.25      0.32      1348\n",
      "           E       0.20      0.07      0.10      1588\n",
      "\n",
      "    accuracy                           0.28      7068\n",
      "   macro avg       0.26      0.29      0.24      7068\n",
      "weighted avg       0.26      0.28      0.24      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  3 0.28706847764572724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.20      0.19      0.20      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.46      0.28      0.35      1348\n",
      "           E       0.20      0.06      0.09      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.27      0.29      0.25      7068\n",
      "weighted avg       0.26      0.29      0.24      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  4 0.2850877192982456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.21      0.19      0.20      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.47      0.28      0.35      1348\n",
      "           E       0.20      0.06      0.09      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.26      0.29      0.25      7068\n",
      "weighted avg       0.26      0.29      0.24      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  5 0.288907753254103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.22      0.20      0.21      1232\n",
      "           C       0.39      0.87      0.54      1400\n",
      "           D       0.48      0.29      0.36      1348\n",
      "           E       0.22      0.06      0.10      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.27      0.30      0.25      7068\n",
      "weighted avg       0.27      0.29      0.25      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  6 0.29060554612337297\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.22      0.20      0.21      1232\n",
      "           C       0.40      0.88      0.55      1400\n",
      "           D       0.48      0.30      0.36      1348\n",
      "           E       0.21      0.06      0.10      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.27      0.30      0.25      7068\n",
      "weighted avg       0.27      0.29      0.25      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  7 0.29485002829654783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.23      0.20      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.49      0.31      0.38      1348\n",
      "           E       0.27      0.07      0.11      1588\n",
      "\n",
      "    accuracy                           0.29      7068\n",
      "   macro avg       0.29      0.30      0.26      7068\n",
      "weighted avg       0.28      0.29      0.25      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  8 0.29640633842671193\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.23      0.20      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.31      0.38      1348\n",
      "           E       0.28      0.07      0.12      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.29      0.30      0.26      7068\n",
      "weighted avg       0.28      0.30      0.25      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  9 0.298811544991511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.23      0.20      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.32      0.38      1348\n",
      "           E       0.32      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.29      0.31      0.26      7068\n",
      "weighted avg       0.29      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  10 0.2995189586870402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.21      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.32      0.39      1348\n",
      "           E       0.31      0.08      0.12      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.29      0.31      0.26      7068\n",
      "weighted avg       0.29      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  11 0.30022637238256933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.20      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.32      0.39      1348\n",
      "           E       0.33      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.26      7068\n",
      "weighted avg       0.29      0.30      0.26      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = distance, Data = std, K의 값  12 0.3024900962082626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.21      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.34      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  13 0.30376344086021506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.04      0.04      1500\n",
      "           B       0.24      0.20      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.36      0.09      0.14      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  14 0.30461233729485004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.05      1500\n",
      "           B       0.25      0.20      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.36      0.09      0.14      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  15 0.3036219581211092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.34      0.40      1348\n",
      "           E       0.36      0.09      0.14      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  16 0.3043293718166384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.05      1500\n",
      "           B       0.24      0.19      0.22      1232\n",
      "           C       0.39      0.88      0.54      1400\n",
      "           D       0.48      0.35      0.40      1348\n",
      "           E       0.37      0.09      0.14      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  17 0.30461233729485004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.04      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.89      0.54      1400\n",
      "           D       0.48      0.35      0.41      1348\n",
      "           E       0.36      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.30      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.30      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  18 0.3060271646859083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.05      0.04      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.89      0.54      1400\n",
      "           D       0.48      0.36      0.41      1348\n",
      "           E       0.36      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.31      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.31      0.26      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  19 0.3065930956423316\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.04      0.04      0.04      1500\n",
      "           B       0.24      0.19      0.21      1232\n",
      "           C       0.39      0.89      0.54      1400\n",
      "           D       0.49      0.37      0.42      1348\n",
      "           E       0.35      0.08      0.13      1588\n",
      "\n",
      "    accuracy                           0.31      7068\n",
      "   macro avg       0.30      0.31      0.27      7068\n",
      "weighted avg       0.30      0.31      0.26      7068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline # 정규화를 위한 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화를 위한 라이브러리2\n",
    "name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15', 'Driver']\n",
    "train_d = pd.read_csv('City_training_normal.csv', names = name)\n",
    "test_d = pd.read_csv('City_test_normal.csv', names = name)\n",
    "\n",
    "#train_d = pd.read_csv('City_median_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_median_test.csv', names = name)\n",
    "\n",
    "#train_d = pd.read_csv('City_mean_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_mean_test.csv', names = name)\n",
    "\n",
    "train_x = train_d[name[0:14]] \n",
    "train_y = train_d[name[15]]\n",
    "test_x = test_d[name[0:14]]\n",
    "test_y = test_d[name[15]]\n",
    "\n",
    "#tmp_train = [[x,y] for x, y in zip(train_x, train_y)]\n",
    "#import random\n",
    "#andom.shuffle(tmp_train)\n",
    "#x_train = [n[0] for n in tmp_train]\n",
    "#y_train = [n[1] for n in tmp_train]\n",
    "\n",
    "#tmp_test = [[x,y] for x, y in zip(test_x, test_y)]\n",
    "#random.shuffle(tmp_test)\n",
    "#x_train = [n[0] for n in tmp_test]\n",
    "#y_train = [n[1] for n in tmp_test]\n",
    "           \n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'uniform') # weight는 uniform, distance 두가지 uniform은 그냥 거리 distance는 거리의 역수 weight에 따른 차이는 0.001정도의 차이\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y) #knn 트레이닝 데이터로 학습\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre)# 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = uniform, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre)) # 답과 예측한 결과로 metrics 출력\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'distance')\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y)\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre) # 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = distance, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre))# 답과 예측한 결과로 metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  5 0.25410299943406905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.28      0.27      0.27      1500\n",
      "           B       0.17      0.14      0.15      1232\n",
      "           C       0.28      0.41      0.33      1400\n",
      "           D       0.18      0.22      0.20      1348\n",
      "           E       0.40      0.22      0.28      1588\n",
      "\n",
      "    accuracy                           0.25      7068\n",
      "   macro avg       0.26      0.25      0.25      7068\n",
      "weighted avg       0.27      0.25      0.25      7068\n",
      "\n",
      "['A' 'A' 'A' ... 'C' 'C' 'C']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline # 정규화를 위한 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화를 위한 라이브러리2\n",
    "name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15', 'Driver']\n",
    "train_d = pd.read_csv('City_training_std.csv', names = name)\n",
    "test_d = pd.read_csv('City_test_std.csv', names = name)\n",
    "\n",
    "#train_d = pd.read_csv('City_median_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_median_test.csv', names = name)\n",
    "\n",
    "#train_d = pd.read_csv('City_mean_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_mean_test.csv', names = name)\n",
    "\n",
    "train_x = train_d[name[0:14]] \n",
    "train_y = train_d[name[15]]\n",
    "test_x = test_d[name[0:14]]\n",
    "test_y = test_d[name[15]]\n",
    "\n",
    "tmp_train = [[x,y] for x, y in zip(train_x, train_y)]\n",
    "import random\n",
    "random.shuffle(tmp_train)\n",
    "x_train = [n[0] for n in tmp_train]\n",
    "y_train = [n[1] for n in tmp_train]\n",
    "\n",
    "tmp_test = [[x,y] for x, y in zip(test_x, test_y)]\n",
    "random.shuffle(tmp_test)\n",
    "x_train = [n[0] for n in tmp_test]\n",
    "y_train = [n[1] for n in tmp_test]\n",
    "           \n",
    "k = 5\n",
    "knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'uniform') # weight는 uniform, distance 두가지 uniform은 그냥 거리 distance는 거리의 역수 weight에 따른 차이는 0.001정도의 차이\n",
    "knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "knnclf.fit(train_x, train_y) #knn 트레이닝 데이터로 학습\n",
    "knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "knnac_score = metrics.accuracy_score(test_y, knnpre)# 답과 예측한 결과로 정확도 측정\n",
    "print(\"KNN weights = uniform, Data = std, K의 값 \",k, knnac_score)\n",
    "print(metrics.classification_report(test_y, knnpre)) # 답과 예측한 결과로 metrics 출력\n",
    "print(knnpre)\n",
    "#for k in range(1, 20, 1):\n",
    "#    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'distance')\n",
    "#    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "#    knnclf.fit(train_x, train_y)\n",
    "#    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "#    knnac_score = metrics.accuracy_score(test_y, knnpre) # 답과 예측한 결과로 정확도 측정\n",
    "#    print(\"KNN weights = distance, Data = std, K의 값 \",k, knnac_score)\n",
    "#    print(metrics.classification_report(test_y, knnpre))# 답과 예측한 결과로 metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  1 0.3661573288058857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.26      0.17      0.20      1232\n",
      "           C       0.53      0.88      0.66      1400\n",
      "           D       0.47      0.65      0.54      1348\n",
      "           E       0.41      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.37      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  2 0.36983588002263723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.23      0.15      0.18      1232\n",
      "           C       0.55      0.92      0.69      1400\n",
      "           D       0.49      0.64      0.56      1348\n",
      "           E       0.49      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.33      7068\n",
      "weighted avg       0.36      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  3 0.3692699490662139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.24      0.15      0.19      1232\n",
      "           C       0.53      0.89      0.66      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.44      0.13      0.21      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.33      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  4 0.36983588002263723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.07      0.06      1500\n",
      "           B       0.24      0.16      0.19      1232\n",
      "           C       0.53      0.90      0.67      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.45      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.33      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  5 0.3616298811544992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.26      0.17      0.20      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.38      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.36      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  6 0.36120543293718166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.25      0.16      0.19      1232\n",
      "           C       0.51      0.86      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.37      0.11      0.17      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  7 0.35964912280701755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.27      0.17      0.21      1232\n",
      "           C       0.50      0.83      0.63      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.36      0.12      0.17      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.33      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  8 0.36063950198075834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.26      0.17      0.20      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.36      0.10      0.16      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  9 0.3624787775891341\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.27      0.18      0.21      1232\n",
      "           C       0.51      0.84      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.37      0.11      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.36      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  10 0.36502546689303905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.26      0.17      0.21      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.39      0.11      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.37      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  11 0.36743067345783814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.29      0.19      0.23      1232\n",
      "           C       0.51      0.84      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.38      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.33      7068\n",
      "weighted avg       0.34      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  12 0.37040181097906055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.29      0.20      0.24      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.67      0.57      1348\n",
      "           E       0.41      0.11      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  13 0.37139219015280134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.31      0.21      0.25      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.57      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  14 0.3735144312393888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.67      0.57      1348\n",
      "           E       0.40      0.11      0.17      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  15 0.37337294850028296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.33      0.22      0.27      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.57      1348\n",
      "           E       0.40      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  16 0.37563667232597625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.33      0.22      0.27      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.67      0.57      1348\n",
      "           E       0.41      0.11      0.18      1588\n",
      "\n",
      "    accuracy                           0.38      7068\n",
      "   macro avg       0.36      0.39      0.34      7068\n",
      "weighted avg       0.36      0.38      0.34      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  17 0.37521222410865873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.43      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.38      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.36      0.38      0.34      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  18 0.3762026032823996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.34      0.23      0.27      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.41      0.11      0.18      1588\n",
      "\n",
      "    accuracy                           0.38      7068\n",
      "   macro avg       0.36      0.39      0.34      7068\n",
      "weighted avg       0.36      0.38      0.34      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  19 0.37139219015280134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.33      0.22      0.27      1232\n",
      "           C       0.51      0.84      0.64      1400\n",
      "           D       0.48      0.67      0.56      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  1 0.3661573288058857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.26      0.17      0.20      1232\n",
      "           C       0.53      0.88      0.66      1400\n",
      "           D       0.47      0.65      0.54      1348\n",
      "           E       0.41      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.37      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  2 0.3661573288058857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.26      0.17      0.20      1232\n",
      "           C       0.53      0.88      0.66      1400\n",
      "           D       0.47      0.65      0.54      1348\n",
      "           E       0.41      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.37      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  3 0.37040181097906055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.25      0.16      0.20      1232\n",
      "           C       0.53      0.89      0.66      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.44      0.13      0.21      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.33      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  4 0.36941143180531977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.25      0.16      0.19      1232\n",
      "           C       0.52      0.88      0.65      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.42      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.38      0.33      7068\n",
      "weighted avg       0.34      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  5 0.3637521222410866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.25      0.17      0.20      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.66      0.56      1348\n",
      "           E       0.39      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  6 0.36262026032823996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.25      0.17      0.20      1232\n",
      "           C       0.51      0.85      0.63      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.37      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.33      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  7 0.36106395019807586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.26      0.17      0.21      1232\n",
      "           C       0.50      0.83      0.63      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.36      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.33      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  8 0.3616298811544992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.06      1500\n",
      "           B       0.27      0.17      0.21      1232\n",
      "           C       0.50      0.84      0.63      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.36      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.33      0.37      0.33      7068\n",
      "weighted avg       0.33      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  9 0.36361063950198075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.27      0.18      0.21      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.37      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  10 0.3638936049801924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.27      0.17      0.21      1232\n",
      "           C       0.51      0.85      0.63      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.38      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.33      7068\n",
      "weighted avg       0.34      0.36      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  11 0.3671477079796265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.29      0.19      0.23      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.48      0.66      0.56      1348\n",
      "           E       0.38      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.34      0.38      0.33      7068\n",
      "weighted avg       0.34      0.37      0.33      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = distance, Data = std, K의 값  12 0.37040181097906055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.29      0.20      0.24      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.34      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  13 0.3699773627617431\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.30      0.20      0.24      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  14 0.371675155631013\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.31      0.21      0.25      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  15 0.37266553480475384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.39      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.35      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  16 0.3739388794567063\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.51      0.86      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.40      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  17 0.3746462931522354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.05      0.05      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.42      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.36      0.37      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  18 0.3760611205432937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.32      0.22      0.26      1232\n",
      "           C       0.51      0.86      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.42      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.38      7068\n",
      "   macro avg       0.36      0.39      0.34      7068\n",
      "weighted avg       0.36      0.38      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  19 0.37436332767402375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.05      0.06      0.05      1500\n",
      "           B       0.33      0.22      0.27      1232\n",
      "           C       0.51      0.85      0.64      1400\n",
      "           D       0.49      0.67      0.56      1348\n",
      "           E       0.40      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.37      7068\n",
      "   macro avg       0.36      0.38      0.34      7068\n",
      "weighted avg       0.35      0.37      0.33      7068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline # 정규화를 위한 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화를 위한 라이브러리2\n",
    "name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15', 'Driver']\n",
    "#train_d = pd.read_csv('City_std_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_std_test.csv', names = name)\n",
    "\n",
    "train_d = pd.read_csv('City_training_median.csv', names = name)\n",
    "test_d = pd.read_csv('City_test_median.csv', names = name)\n",
    "\n",
    "#train_d = pd.read_csv('City_mean_training.csv', names = name)\n",
    "#test_d = pd.read_csv('City_mean_test.csv', names = name)\n",
    "\n",
    "train_x = train_d[name[0:14]] \n",
    "train_y = train_d[name[15]]\n",
    "test_x = test_d[name[0:14]]\n",
    "test_y = test_d[name[15]]\n",
    "\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'uniform') # weight는 uniform, distance 두가지 uniform은 그냥 거리 distance는 거리의 역수 weight에 따른 차이는 0.001정도의 차이\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y) #knn 트레이닝 데이터로 학습\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre)# 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = uniform, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre)) # 답과 예측한 결과로 metrics 출력\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'distance')\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y)\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre) # 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = distance, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre))# 답과 예측한 결과로 metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  1 0.388228636106395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.05      1500\n",
      "           B       0.28      0.26      0.27      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.43      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.35      0.40      0.35      7068\n",
      "weighted avg       0.35      0.39      0.34      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  2 0.3869552914544426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.28      0.26      0.27      1232\n",
      "           C       0.52      0.86      0.65      1400\n",
      "           D       0.50      0.69      0.58      1348\n",
      "           E       0.44      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.36      0.40      0.35      7068\n",
      "weighted avg       0.36      0.39      0.34      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  3 0.3914827391058291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.06      1500\n",
      "           B       0.29      0.27      0.28      1232\n",
      "           C       0.52      0.85      0.65      1400\n",
      "           D       0.48      0.69      0.57      1348\n",
      "           E       0.43      0.15      0.22      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.36      0.40      0.35      7068\n",
      "weighted avg       0.36      0.39      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  4 0.39176570458404075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.06      0.06      1500\n",
      "           B       0.31      0.26      0.28      1232\n",
      "           C       0.53      0.87      0.66      1400\n",
      "           D       0.49      0.69      0.57      1348\n",
      "           E       0.47      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.37      0.40      0.36      7068\n",
      "weighted avg       0.37      0.39      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  5 0.3938879456706282\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.32      0.27      0.29      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.42      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.36      0.40      0.36      7068\n",
      "weighted avg       0.36      0.39      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  6 0.39572722127900395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.33      0.26      0.29      1232\n",
      "           C       0.54      0.88      0.67      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.46      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.36      7068\n",
      "weighted avg       0.37      0.40      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  7 0.39714204867006225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.34      0.27      0.31      1232\n",
      "           C       0.54      0.87      0.66      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.42      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.36      7068\n",
      "weighted avg       0.37      0.40      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  8 0.39799094510469724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.07      1500\n",
      "           B       0.36      0.28      0.31      1232\n",
      "           C       0.54      0.87      0.67      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.43      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  9 0.3960101867572156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.07      1500\n",
      "           B       0.37      0.29      0.32      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.39      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.36      7068\n",
      "weighted avg       0.36      0.40      0.35      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  10 0.3988398415393322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.38      0.29      0.33      1232\n",
      "           C       0.54      0.86      0.66      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.41      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  11 0.39855687606112056\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.39      0.30      0.34      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  12 0.3968590831918506\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.39      0.29      0.33      1232\n",
      "           C       0.54      0.85      0.66      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.40      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  13 0.3984153933220147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.07      1500\n",
      "           B       0.41      0.31      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.38      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  14 0.4008205998868138\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.41      0.31      0.35      1232\n",
      "           C       0.54      0.85      0.66      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.38      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  15 0.3984153933220147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.41      0.30      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.38      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  16 0.40110356536502545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.42      0.31      0.36      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.38      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  17 0.3975664968873797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.42      0.31      0.35      1232\n",
      "           C       0.53      0.83      0.65      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.38      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  18 0.3988398415393322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.42      0.31      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.38      0.40      0.36      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  19 0.39714204867006225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.42      0.31      0.36      1232\n",
      "           C       0.53      0.83      0.64      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.37      0.12      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  1 0.388228636106395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.05      1500\n",
      "           B       0.28      0.26      0.27      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.43      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.35      0.40      0.35      7068\n",
      "weighted avg       0.35      0.39      0.34      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  2 0.388228636106395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.05      1500\n",
      "           B       0.28      0.26      0.27      1232\n",
      "           C       0.52      0.85      0.64      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.43      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.35      0.40      0.35      7068\n",
      "weighted avg       0.35      0.39      0.34      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  3 0.3914827391058291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.06      1500\n",
      "           B       0.29      0.27      0.28      1232\n",
      "           C       0.52      0.85      0.65      1400\n",
      "           D       0.48      0.69      0.57      1348\n",
      "           E       0.43      0.15      0.22      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.36      0.40      0.35      7068\n",
      "weighted avg       0.36      0.39      0.35      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  4 0.39134125636672323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.06      1500\n",
      "           B       0.30      0.27      0.28      1232\n",
      "           C       0.52      0.85      0.65      1400\n",
      "           D       0.48      0.69      0.57      1348\n",
      "           E       0.43      0.15      0.22      1588\n",
      "\n",
      "    accuracy                           0.39      7068\n",
      "   macro avg       0.36      0.40      0.35      7068\n",
      "weighted avg       0.36      0.39      0.35      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  5 0.3950198075834748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.06      0.05      0.06      1500\n",
      "           B       0.32      0.27      0.29      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.42      0.15      0.22      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.36      0.41      0.36      7068\n",
      "weighted avg       0.36      0.40      0.35      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  6 0.3950198075834748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.32      0.27      0.29      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.42      0.15      0.22      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.36      0.41      0.36      7068\n",
      "weighted avg       0.36      0.40      0.35      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  7 0.3984153933220147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.34      0.28      0.31      1232\n",
      "           C       0.54      0.87      0.66      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.42      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.36      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  8 0.398981324278438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.06      1500\n",
      "           B       0.34      0.28      0.31      1232\n",
      "           C       0.53      0.86      0.66      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.42      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.36      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  9 0.398981324278438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.07      1500\n",
      "           B       0.37      0.29      0.32      1232\n",
      "           C       0.53      0.86      0.66      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.41      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  10 0.3977079796264856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.06      0.07      1500\n",
      "           B       0.36      0.28      0.32      1232\n",
      "           C       0.53      0.86      0.66      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.40      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.36      7068\n",
      "weighted avg       0.36      0.40      0.35      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  11 0.40053763440860213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.38      0.30      0.33      1232\n",
      "           C       0.53      0.85      0.66      1400\n",
      "           D       0.49      0.70      0.57      1348\n",
      "           E       0.40      0.14      0.21      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = distance, Data = std, K의 값  12 0.3984153933220147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.07      0.07      0.07      1500\n",
      "           B       0.39      0.29      0.34      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.48      0.70      0.57      1348\n",
      "           E       0.39      0.14      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.37      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  13 0.3982739105829089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.07      1500\n",
      "           B       0.39      0.29      0.34      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.14      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  14 0.40011318619128466\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.07      1500\n",
      "           B       0.40      0.30      0.34      1232\n",
      "           C       0.53      0.85      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  15 0.39997170345217886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.07      1500\n",
      "           B       0.41      0.30      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.39      0.14      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  16 0.39954725523486134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.07      1500\n",
      "           B       0.41      0.30      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.71      0.58      1348\n",
      "           E       0.39      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  17 0.39954725523486134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.07      0.08      1500\n",
      "           B       0.42      0.31      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.70      0.58      1348\n",
      "           E       0.38      0.13      0.20      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  18 0.3992642897566497\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.41      0.30      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.71      0.58      1348\n",
      "           E       0.38      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  19 0.39799094510469724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.08      0.08      0.08      1500\n",
      "           B       0.41      0.30      0.35      1232\n",
      "           C       0.53      0.84      0.65      1400\n",
      "           D       0.49      0.71      0.58      1348\n",
      "           E       0.38      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.40      7068\n",
      "   macro avg       0.38      0.41      0.37      7068\n",
      "weighted avg       0.37      0.40      0.36      7068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline # 정규화를 위한 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화를 위한 라이브러리2\n",
    "name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15', 'Driver']\n",
    "\n",
    "train_d = pd.read_csv('City_training_mean.csv', names = name)\n",
    "test_d = pd.read_csv('City_test_mean.csv', names = name)\n",
    "\n",
    "train_x = train_d[name[0:14]] \n",
    "train_y = train_d[name[15]]\n",
    "test_x = test_d[name[0:14]]\n",
    "test_y = test_d[name[15]]\n",
    "\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'uniform') # weight는 uniform, distance 두가지 uniform은 그냥 거리 distance는 거리의 역수 weight에 따른 차이는 0.001정도의 차이\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y) #knn 트레이닝 데이터로 학습\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre)# 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = uniform, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre)) # 답과 예측한 결과로 metrics 출력\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'distance')\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y)\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre) # 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = distance, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre))# 답과 예측한 결과로 metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  1 0.34125636672325976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.09      0.08      0.08      1500\n",
      "           B       0.41      0.33      0.36      1232\n",
      "           C       0.43      0.65      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.28      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.34      7068\n",
      "   macro avg       0.32      0.35      0.32      7068\n",
      "weighted avg       0.32      0.34      0.31      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  2 0.34125636672325976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.11      0.11      0.11      1500\n",
      "           B       0.37      0.34      0.35      1232\n",
      "           C       0.45      0.67      0.54      1400\n",
      "           D       0.41      0.53      0.46      1348\n",
      "           E       0.28      0.12      0.16      1588\n",
      "\n",
      "    accuracy                           0.34      7068\n",
      "   macro avg       0.32      0.35      0.32      7068\n",
      "weighted avg       0.32      0.34      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  3 0.350169779286927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.11      0.11      1500\n",
      "           B       0.42      0.33      0.37      1232\n",
      "           C       0.44      0.66      0.52      1400\n",
      "           D       0.41      0.57      0.48      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.33      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  4 0.3524335031126203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.11      0.11      0.11      1500\n",
      "           B       0.41      0.34      0.38      1232\n",
      "           C       0.44      0.68      0.54      1400\n",
      "           D       0.43      0.57      0.49      1348\n",
      "           E       0.28      0.12      0.16      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.34      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  5 0.3562535370684776\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.11      0.11      1500\n",
      "           B       0.45      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.53      1400\n",
      "           D       0.41      0.57      0.48      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  6 0.35667798528579514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.11      0.12      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.44      0.68      0.54      1400\n",
      "           D       0.41      0.56      0.48      1348\n",
      "           E       0.31      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  7 0.35271646859083194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.11      0.12      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.42      0.66      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.34      0.36      0.34      7068\n",
      "weighted avg       0.33      0.35      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  8 0.3585172608941709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.12      0.12      1500\n",
      "           B       0.44      0.36      0.40      1232\n",
      "           C       0.44      0.68      0.53      1400\n",
      "           D       0.41      0.56      0.48      1348\n",
      "           E       0.32      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.35      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  9 0.3575268817204301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.12      0.12      1500\n",
      "           B       0.44      0.36      0.40      1232\n",
      "           C       0.43      0.67      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  10 0.3571024335031126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.44      0.36      0.40      1232\n",
      "           C       0.43      0.68      0.53      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.12      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  11 0.35526315789473684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.33      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  12 0.35738539898132426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.13      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.43      0.68      0.53      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.12      0.17      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  13 0.35356536502546687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.65      0.51      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.29      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.34      0.36      0.34      7068\n",
      "weighted avg       0.33      0.35      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  14 0.35667798528579514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.13      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.66      0.52      1400\n",
      "           D       0.41      0.56      0.47      1348\n",
      "           E       0.30      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  15 0.35724391624221846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.13      0.14      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.65      0.51      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = uniform, Data = std, K의 값  16 0.35002829654782114\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.13      0.14      1500\n",
      "           B       0.43      0.36      0.39      1232\n",
      "           C       0.42      0.66      0.51      1400\n",
      "           D       0.39      0.52      0.44      1348\n",
      "           E       0.30      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.34      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.32      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  17 0.3578098471986418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.40      1232\n",
      "           C       0.41      0.65      0.51      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  18 0.3561120543293718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.41      0.66      0.50      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = uniform, Data = std, K의 값  19 0.3491794001131862\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.43      0.36      0.39      1232\n",
      "           C       0.41      0.66      0.50      1400\n",
      "           D       0.39      0.52      0.45      1348\n",
      "           E       0.29      0.14      0.18      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.33      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  1 0.34125636672325976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.09      0.08      0.08      1500\n",
      "           B       0.41      0.33      0.36      1232\n",
      "           C       0.43      0.65      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.28      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.34      7068\n",
      "   macro avg       0.32      0.35      0.32      7068\n",
      "weighted avg       0.32      0.34      0.31      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  2 0.34125636672325976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.09      0.08      0.08      1500\n",
      "           B       0.41      0.33      0.36      1232\n",
      "           C       0.43      0.65      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.28      0.13      0.18      1588\n",
      "\n",
      "    accuracy                           0.34      7068\n",
      "   macro avg       0.32      0.35      0.32      7068\n",
      "weighted avg       0.32      0.34      0.31      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  3 0.34946236559139787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.10      0.11      1500\n",
      "           B       0.42      0.33      0.37      1232\n",
      "           C       0.44      0.66      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.33      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  4 0.34818902093944537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.11      0.10      0.11      1500\n",
      "           B       0.42      0.33      0.37      1232\n",
      "           C       0.43      0.65      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.29      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.35      7068\n",
      "   macro avg       0.33      0.36      0.33      7068\n",
      "weighted avg       0.33      0.35      0.32      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  5 0.3571024335031126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.11      0.11      1500\n",
      "           B       0.45      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.53      1400\n",
      "           D       0.41      0.57      0.47      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  6 0.35526315789473684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.12      0.11      0.11      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.43      0.66      0.52      1400\n",
      "           D       0.41      0.57      0.48      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.33      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  7 0.35526315789473684\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.11      0.12      1500\n",
      "           B       0.44      0.34      0.39      1232\n",
      "           C       0.43      0.66      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  8 0.35724391624221846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.11      0.12      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.52      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.31      0.14      0.20      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  9 0.35738539898132426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.13      0.12      0.12      1500\n",
      "           B       0.45      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.32      0.14      0.20      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  10 0.3579513299377476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.45      0.35      0.39      1232\n",
      "           C       0.43      0.67      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.31      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  11 0.3555461233729485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.44      0.35      0.39      1232\n",
      "           C       0.43      0.66      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.33      0.36      0.33      7068\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN weights = distance, Data = std, K의 값  12 0.35724391624221846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.67      0.52      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.13      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  13 0.35568760611205436\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.65      0.51      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.33      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  14 0.35681946802490094\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.14      0.12      0.13      1500\n",
      "           B       0.45      0.36      0.40      1232\n",
      "           C       0.42      0.66      0.51      1400\n",
      "           D       0.40      0.56      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  15 0.3576683644595359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.40      1232\n",
      "           C       0.41      0.65      0.50      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  16 0.3575268817204301\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.40      1232\n",
      "           C       0.41      0.65      0.51      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  17 0.3578098471986418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.40      1232\n",
      "           C       0.41      0.65      0.50      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  18 0.35880022637238257\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.41      1232\n",
      "           C       0.41      0.66      0.50      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n",
      "KNN weights = distance, Data = std, K의 값  19 0.35809281267685344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.15      0.12      0.13      1500\n",
      "           B       0.46      0.36      0.40      1232\n",
      "           C       0.41      0.65      0.50      1400\n",
      "           D       0.40      0.57      0.47      1348\n",
      "           E       0.30      0.14      0.19      1588\n",
      "\n",
      "    accuracy                           0.36      7068\n",
      "   macro avg       0.34      0.37      0.34      7068\n",
      "weighted avg       0.34      0.36      0.33      7068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline # 정규화를 위한 라이브러리\n",
    "from sklearn.preprocessing import StandardScaler # 정규화를 위한 라이브러리2\n",
    "\n",
    "name = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30', '31','32','33','34','35','36','37','38','39','40','41','42','43','44','45', 'Driver']\n",
    "#1~15 std, 16~30 median, 31~45 mean\n",
    "train_d = pd.read_csv('City_training_ALL.csv', names = name)\n",
    "test_d = pd.read_csv('City_test_ALL.csv', names = name)\n",
    "\n",
    "train_x = train_d[name[0:44]] \n",
    "train_y = train_d[name[45]]\n",
    "test_x = test_d[name[0:44]]\n",
    "test_y = test_d[name[45]]\n",
    "\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'uniform') # weight는 uniform, distance 두가지 uniform은 그냥 거리 distance는 거리의 역수 weight에 따른 차이는 0.001정도의 차이\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y) #knn 트레이닝 데이터로 학습\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre)# 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = uniform, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre)) # 답과 예측한 결과로 metrics 출력\n",
    "\n",
    "for k in range(1, 20, 1):\n",
    "    knnclf = KNeighborsClassifier(n_neighbors = k, weights= 'distance')\n",
    "    knnclf = Pipeline([('norm', StandardScaler()), ('knn', knnclf)])# nomarlization\n",
    "    knnclf.fit(train_x, train_y)\n",
    "    knnpre = knnclf.predict(test_x) #knnpre ? knn이 예측한 라벨 부분 이 라벨과 test_y간 비교 test_y는 정답\n",
    "    knnac_score = metrics.accuracy_score(test_y, knnpre) # 답과 예측한 결과로 정확도 측정\n",
    "    print(\"KNN weights = distance, Data = std, K의 값 \",k, knnac_score)\n",
    "    print(metrics.classification_report(test_y, knnpre))# 답과 예측한 결과로 metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
